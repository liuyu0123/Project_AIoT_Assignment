import cv2
import numpy as np
import argparse
import os
from utils import  Yolov8Pose

def main():
    parser = argparse.ArgumentParser(description='YOLOv8-Pose ONNX Inference')
    parser.add_argument('--model', type=str, default='../model/yolov8n-pose.q.onnx', help='Path to the YOLOv8 ONNX model')
    parser.add_argument('--image', type=str, default='../data/test.jpg', help='Path to the input image')
    parser.add_argument('--use-camera', action='store_true', help='Use camera as input')
    parser.add_argument('--camera-path', type=str, default='/dev/video20', help='Camera device path (default: /dev/video20)')
    parser.add_argument('--conf-threshold', type=float, default=0.2, help='Confidence threshold')    
    parser.add_argument('--iou-threshold', type=float, default=0.45, help='IOU threshold')    
    args = parser.parse_args()

    # Create detector 
    detector = Yolov8Pose(args.model,args.conf_threshold,args.iou_threshold)

    if args.use_camera:        
        # 1. è§£æå‚æ•°ï¼ˆåªä¿ç•™æ ¸å¿ƒåŠŸèƒ½ï¼Œé€‚é…äºæ‘„åƒå¤´ï¼Œé€‚é…äºè®¾å¤‡ï¼‰
        print(f"ğŸ¥ å°è¯•æ‰“å¼€æ‘„åƒå¤´: {args.camera_path}")
        
        # 2. åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ˆç®€ä¿æ¨¡å‹è·¯å¾„æ­£ç¡®ï¼‰
        if not os.path.exists(args.model):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{args.model}")
            return
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {args.model}")
        
        # 3. å¼ºåˆ¶æŒ‡å®š /dev/video20 æ‰“å¼€æ‘„åƒå¤´ï¼ˆæ ¸å¿ƒé€‚é…ï¼‰
        camera_path = args.camera_path
        print(f"ğŸ“· å°è¯•æ‰“å¼€æ‘„åƒå¤´: {camera_path}")
        
        # å…³é”®ï¼šæ·»åŠ  OpenCV æ‘„åƒå¤´å‚æ•°é…ç½®ï¼ˆè§£å†³å…¼å®¹æ€§è®¾å¤‡å…¼å®¹æ€§é—®é¢˜ï¼‰
        cap = cv2.VideoCapture(camera_path, cv2.CAP_V4L2)  # CAP_V4L2 æ˜¯ Linux ä¸“ç”¨è§†é¢‘é©±åŠ¨ï¼Œé€‚é…è®¾å¤‡å…¼å®¹
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)   # å›ºå®šåˆ†è¾¨ç‡ï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # å›ºå®šåˆ†è¾¨ç‡ï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜  
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)      # å‡å°‘ç¼“å†²åŒºï¼Œé™ä½å»¶è¿Ÿ
        
        # 4. æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´è®¾å¤‡")
            print("ğŸ’¡ å¯å°è¯•çš„è®¾å¤‡è·¯å¾„: /dev/video0, /dev/video1, /dev/video2, /dev/video3, /dev/video20, /dev/video21")
            return
            
        print("âœ… æ‘„åƒå¤´æ‰“å¼€æˆåŠŸï¼Œå¼€å§‹å§¿æ€æ£€æµ‹...")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•ä»æ‘„åƒå¤´è¯»å–å¸§")
                break
                
            # å§¿æ€æ£€æµ‹æ¨ç†
            result_image = detector.infer(frame)

            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('YOLOv8-Pose Inference', result_image)

            # æŒ‰ 'q' é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
    else:
        if args.image is None:
            print("Please provide either an image path or use the --use-camera option.")
            return
        # Load image
        image = cv2.imread(args.image)
        if image is None:
            print(f"Failed to read image: {args.image}")
            return

        # Inference
        result_image = detector.infer(image)

        # Save result image
        cv2.imwrite('result.jpg', result_image)
        print("Results saved to result.jpg")

if __name__ == "__main__":
    main()