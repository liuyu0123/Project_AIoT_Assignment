import cv2
import numpy as np
import argparse
import os
from utils import  YOLOWORLD

def main():
    parser = argparse.ArgumentParser(description='YOLO-World ONNX Inference')
    parser.add_argument('--model', type=str, default='../model/yolov8s-worldv2.q.onnx', help='Path to the YOLOv8 ONNX model')
    parser.add_argument('--image', type=str, default='../data/test.jpg', help='Path to the input image')
    parser.add_argument('--use-camera', action='store_true', help='Use camera as input')
    parser.add_argument('--camera-path', type=str, default='/dev/video20', help='Camera device path (default: /dev/video20)')
    parser.add_argument('--conf-threshold', type=float, default=0.2, help='Confidence threshold')    
    parser.add_argument('--iou-threshold', type=float, default=0.45, help='IoU threshold')
    parser.add_argument('--classes', nargs='+', type=str, default=['people'],help='Input class names: people car telephone')

    args = parser.parse_args()

    # Create detector 
    detector = YOLOWORLD(args.model,args.conf_threshold,args.iou_threshold)
    class_names = args.classes    
    detector.set_classes(class_names)

    if args.use_camera:        
        # 1. è§£æå‚æ•°ï¼ˆé€‚é…YOLO-Worldå¼€æ”¾è¯æ±‡æ£€æµ‹ï¼‰
        print(f"ğŸ¥ å°è¯•æ‰“å¼€æ‘„åƒå¤´: {args.camera_path}")
        print(f"ğŸ·ï¸  æ£€æµ‹ç±»åˆ«: {', '.join(class_names)}")
        
        # 2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
        if not os.path.exists(args.model):
            print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{args.model}")
            return
        
        print(f"âœ… YOLO-Worldæ¨¡å‹åŠ è½½æˆåŠŸ: {args.model}")
        
        # 3. ä¼˜åŒ–çš„æ‘„åƒå¤´é…ç½®
        camera_path = args.camera_path
        print(f"ğŸ“· å°è¯•æ‰“å¼€æ‘„åƒå¤´: {camera_path}")
        
        # å…³é”®ï¼šä½¿ç”¨CAP_V4L2åç«¯å’Œä¼˜åŒ–å‚æ•°
        # cap = cv2.VideoCapture(camera_path, cv2.CAP_V4L2)
        cap = cv2.VideoCapture(0)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)   # å›ºå®šåˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)  # å›ºå®šåˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)      # å‡å°‘ç¼“å†²åŒºå»¶è¿Ÿ
        
        # 4. æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
        if not cap.isOpened():
            print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´è®¾å¤‡")
            print("ğŸ’¡ å¯å°è¯•çš„è®¾å¤‡è·¯å¾„: /dev/video0, /dev/video1, /dev/video2, /dev/video3, /dev/video20, /dev/video21")
            return
        
        print("âœ… æ‘„åƒå¤´æ‰“å¼€æˆåŠŸï¼Œå¼€å§‹YOLO-Worldå¼€æ”¾è¯æ±‡æ£€æµ‹...")
        print(f"ğŸ¯ å½“å‰æ£€æµ‹ç±»åˆ«: {', '.join(class_names)}")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•ä»æ‘„åƒå¤´è¯»å–å¸§")
                break
                
            # ğŸŒŸ YOLO-Worldæ¨ç†ï¼šä¼ å…¥è‡ªå®šä¹‰ç±»åˆ«
            result_image = detector.infer(frame, class_names)

            # æ˜¾ç¤ºç»“æœ
            cv2.imshow('YOLO-World Inference', result_image)

            # æŒ‰ 'q' é€€å‡º
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
    else:
        if args.image is None:
            print("Please provide either an image path or use the --use-camera option.")
            return
        # Load image
        image = cv2.imread(args.image)
        if image is None:
            print(f"Failed to read image: {args.image}")
            return

        # Inference
        result_image = detector.infer(image,class_names)

        # Save result image
        cv2.imwrite('result.jpg', result_image)
        print("Results saved to result.jpg")

if __name__ == "__main__":
    main()